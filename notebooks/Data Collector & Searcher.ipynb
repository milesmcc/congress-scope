{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import hashlib\n",
    "from tqdm import tqdm\n",
    "import unicodecsv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5hash(item):\n",
    "    m = hashlib.md5()\n",
    "    m.update(json.dumps(item[\"metadata\"][\"id\"]).encode('ascii'))\n",
    "    m.update(json.dumps(item[\"text\"]).encode('ascii'))\n",
    "    m.update(json.dumps(item[\"metadata\"][\"header\"]).encode('ascii'))\n",
    "    return m.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('../data/'):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        if path.endswith(\".json\") and (\"/110/\" in path or \"/111/\" in path):\n",
    "            with open(path, \"r\") as infile:\n",
    "                data = json.load(infile)\n",
    "                congress = int(re.search(r\"data\\/(\\d+)\\/output\", path).group(1))\n",
    "                metadata = {\n",
    "                    \"header\": data[\"header\"],\n",
    "                    \"id\": data[\"id\"],\n",
    "                    \"title\": data[\"title\"],\n",
    "                    \"document_title\": data[\"doc_title\"],\n",
    "                    \"congress\": congress\n",
    "                }\n",
    "                for item in data[\"content\"]:\n",
    "                    item[\"metadata\"] = metadata\n",
    "                    item[\"hash\"] = md5hash(item)\n",
    "                    items.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/corpus.json\", \"w\") as outfile:\n",
    "    json.dump(items, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_search_results(items, file):\n",
    "    with open(file, \"wb\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"HASH\", \"SPEAKER\", \"BIOGUIDE\", \"DATE\", \"TITLE\", \"TEXT\"])\n",
    "        for item in items:\n",
    "            date = \"-\".join([item[\"metadata\"][\"header\"][\"day\"], item[\"metadata\"][\"header\"][\"month\"], item[\"metadata\"][\"header\"][\"year\"]])\n",
    "            writer.writerow([item[\"hash\"], item[\"speaker\"], item[\"speaker_bioguide\"], date, item[\"metadata\"][\"title\"], item[\"text\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iraq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999390/999390 [00:01<00:00, 545182.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search returned 13486 results.\n"
     ]
    }
   ],
   "source": [
    "matched_items = []\n",
    "for item in tqdm(items):\n",
    "    if \"speaker_bioguide\" not in item:\n",
    "        item[\"speaker_bioguide\"] = None\n",
    "    if \"iraq\" in item[\"text\"].lower() and item[\"metadata\"][\"congress\"] == 110:\n",
    "        matched_items.append(item)\n",
    "with open(\"../data/iraq.json\", \"w\") as outfile:\n",
    "    json.dump(matched_items, outfile)\n",
    "write_search_results(matched_items, \"../data/iraq.csv\")\n",
    "print(\"Search returned %s results.\" % len(matched_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afghanistan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999390/999390 [00:01<00:00, 543482.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search returned 4786 results.\n"
     ]
    }
   ],
   "source": [
    "matched_items = []\n",
    "for item in tqdm(items):\n",
    "    if \"speaker_bioguide\" not in item:\n",
    "        item[\"speaker_bioguide\"] == None\n",
    "    if \"afghanistan\" in item[\"text\"].lower() and item[\"metadata\"][\"congress\"] == 111:\n",
    "        matched_items.append(item)\n",
    "with open(\"../data/afghanistan.json\", \"w\") as outfile:\n",
    "    json.dump(matched_items, outfile)\n",
    "write_search_results(matched_items, \"../data/afghanistan.csv\")\n",
    "print(\"Search returned %s results.\" % len(matched_items))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
